{
  "hash": "c385c420c1c40daac8facc4ab2c03fa1",
  "result": {
    "markdown": "---\ntitle: \"Post 5 - Anomaly/outlier detection\"\nformat:\n  html:\n    self-contained: true\n    toc: true\n    theme: cosmo\nauthor: \"Charan Teja Chelle\"\ndate: \"2023-12-04\"\ncategories: [code, data visualization]\nimage: \"anomalydetection.jpg\"\n---\n\n# Introduction\n\nAnomaly detection, aka outlier detection is a machine learning task that involves identifying patterns or instances in data that do not confine to the expected behavior. These instances are considered anomalies or outliers as they significantly deviate from the majority of data. Anomaly detection can be done in two ways namely Supervised anomaly detection and Unsupervised anomaly detection. Outlier detection plays a vital role in ensuring the security, integrity and reliability of systems by pointing out suspicious or unforeseen events. Few real-time applications of anomaly detection include fraud detection, network security, manufacturing and quality control, healthcare, etc.,\n\n# Code\n\nThis code sample demonstates a simple anomaly detection code using 'Isolation Forest' algorithm and toy dataset. We will initially be generating a toy dataset with both normal and anomalous data points, then train an Isolation Forest model, and ultimately visualize the results. The data visualizations obtained after running the below code chunk clearly helps us understand how the Isolation Forest algorithm separates normal and anomalous data points.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plot\nfrom sklearn.ensemble import IsolationForest\n\n# Create a toy dataset with normal and anomalous data points\nnp.random.seed(42)\nnormal_data = np.random.normal(loc=0, scale=1, size=(800, 2))  # Normal data points\nanomalous_data = np.random.normal(loc=5, scale=1, size=(20, 2))  # Anomalous data points\n\n# Merge normal and anomalous data\ndata = np.vstack([normal_data, anomalous_data])\n\n# Shuffle the data\nnp.random.shuffle(data)\n\n# Visualize the dataset\nplot.figure(figsize=(9, 7))\nplot.scatter(data[:, 0], data[:, 1], c='b', marker='o', label='Normal Data', alpha=0.7)\nplot.scatter(anomalous_data[:, 0], anomalous_data[:, 1], c='r', marker='x', label='Anomalous Data')\nplot.title('Toy Dataset for Anomaly Detection')\nplot.xlabel('Feature 1')\nplot.ylabel('Feature 2')\nplot.legend()\nplot.show()\n\n# Train an Isolation Forest model by setting 'contamination' parameter to expected proportion of anomalies in dataset\nisolation_forest = IsolationForest(contamination=0.02, random_state=42)\nisolation_forest.fit(data)\n\n# Predict anomalies (1 for normal, -1 for anomaly)\npredictions = isolation_forest.predict(data)\n\n# Visualize the Isolation Forest results\nplot.figure(figsize=(9, 7))\n\n# Plot normal data points\nplot.scatter(data[predictions == 1][:, 0], data[predictions == 1][:, 1], c='b', marker='o', label='Normal Data')\n\n# Plot anomalous data points\nplot.scatter(data[predictions == -1][:, 0], data[predictions == -1][:, 1], c='r', marker='x', label='Anomalous Data')\n\n# Highlight true anomalous data points\nplot.scatter(anomalous_data[:, 0], anomalous_data[:, 1], c='g', marker='*', s=200, label='True Anomalies')\n\nplot.title('Isolation Forest Anomaly Detection')\nplot.xlabel('Feature 1')\nplot.ylabel('Feature 2')\nplot.legend()\nplot.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=736 height=597}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-2.png){width=736 height=597}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}